{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization du vocabulaire !\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulaire = open('dictionnaire.txt','r', encoding='utf-8').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'à afin autant automatique automatisées autres aux bien calcul ces comme complexes compression connaissance considérée danalyse dans de den densembles des dincertitude discipline disjointes domaines données elle emploie en est et extraire formes généralement généraux haute informations informatique intéressantes la lanalytique lapprentissage larges le les lextraction limitée linformation lingénierie masse mathématiques méthodes modèles modélisation moins ne notamment objectif ou particulièrement pas performance plus plusieurs possible potentiellement premier principalement probabilistes produire programmation prophétique que qui reconnaissance sadaptent science signal soit sont source sources statistique stockage techniques technologie termes théorie théories tirées traitement tri utiles visualisation wikipédia'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulaire\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_voc = vocabulaire.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['à',\n",
       " 'afin',\n",
       " 'autant',\n",
       " 'automatique',\n",
       " 'automatisées',\n",
       " 'autres',\n",
       " 'aux',\n",
       " 'bien',\n",
       " 'calcul',\n",
       " 'ces']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_voc[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remplacement caractères Spéciaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En termes généraux, la scence des données est l'extraction de conaissance d'ensembles de données.   \n",
      " \n",
      "Elle emploie des techniques et des théories tirées de plusieurs autres domaines plus larges des mathématiques, la statistique principalement, la téorie de l'information et la technologie de l'information, notamment le traitement de signal, des modèles probabilistes, l'apprentissage automatique, l'apprentissage statistiqe, la programmation informatique, l'ingénierie de données, la reconnaissance de formes et l'apprentissage, la visualisation, l'analytique prophétique, la modélisation d'incertitude, le stokage de données, la compression de données et le calcul à haute performance. \n",
      " \n",
      "Les méthodes qui s'adaptent aux données de masse sont particulièrement intéressantes dans la science des données, bien que la dicipline ne soit généralement pas considérée come limitée à ces données.   \n",
      " \n",
      "Le premier objectif est de produire des méthodes automatisées, autant que possible de tri et d'analyse de données de masse et de sources plus ou moins complexes ou disjointes de données, afin d'en extraire des informations utiles ou potentiellement utiles. Source Wikipédia\n"
     ]
    }
   ],
   "source": [
    "text = open('texte.txt','r',encoding='utf-8').read()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace('a remplacer', 'remplace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = 'Python,est,cool'\n",
    "test = test.replace(',',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python est cool\n"
     ]
    }
   ],
   "source": [
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En termes généraux, la scence des données est l'extraction de conaissance d'ensembles de données.   \n",
      " \n",
      "Elle emploie des techniques et des théories tirées de plusieurs autres domaines plus larges des mathématiques, la statistique principalement, la téorie de l'information et la technologie de l'information, notamment le traitement de signal, des modèles probabilistes, l'apprentissage automatique, l'apprentissage statistiqe, la programmation informatique, l'ingénierie de données, la reconnaissance de formes et l'apprentissage, la visualisation, l'analytique prophétique, la modélisation d'incertitude, le stokage de données, la compression de données et le calcul à haute performance. \n",
      " \n",
      "Les méthodes qui s'adaptent aux données de masse sont particulièrement intéressantes dans la science des données, bien que la dicipline ne soit généralement pas considérée come limitée à ces données.   \n",
      " \n",
      "Le premier objectif est de produire des méthodes automatisées, autant que possible de tri et d'analyse de données de masse et de sources plus ou moins complexes ou disjointes de données, afin d'en extraire des informations utiles ou potentiellement utiles. Source Wikipédia\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python est incroyable.\n"
     ]
    }
   ],
   "source": [
    "def clean_text(string_value):\n",
    "    cleaned_value = string_value.replace(',',' ')\n",
    "    return(cleaned_value)\n",
    "\n",
    "sentence = 'Python,est,incroyable.'\n",
    "sentence = clean_text(sentence)\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En termes généraux, la scence des données est l'extraction de conaissance d'ensembles de données.   \n",
      " \n",
      "Elle emploie des techniques et des théories tirées de plusieurs autres domaines plus larges des mathématiques, la statistique principalement, la téorie de l'information et la technologie de l'information, notamment le traitement de signal, des modèles probabilistes, l'apprentissage automatique, l'apprentissage statistiqe, la programmation informatique, l'ingénierie de données, la reconnaissance de formes et l'apprentissage, la visualisation, l'analytique prophétique, la modélisation d'incertitude, le stokage de données, la compression de données et le calcul à haute performance. \n",
      " \n",
      "Les méthodes qui s'adaptent aux données de masse sont particulièrement intéressantes dans la science des données, bien que la dicipline ne soit généralement pas considérée come limitée à ces données.   \n",
      " \n",
      "Le premier objectif est de produire des méthodes automatisées, autant que possible de tri et d'analyse de données de masse et de sources plus ou moins complexes ou disjointes de données, afin d'en extraire des informations utiles ou potentiellement utiles. Source Wikipédia\n"
     ]
    }
   ],
   "source": [
    "def clean_text(string):\n",
    "    cleaned_text = string.replace(',','')\n",
    "    cleaned_text = cleaned_text.replace('.','')\n",
    "    cleaned_text = cleaned_text.replace('\\n', '')\n",
    "    cleaned_text = cleaned_text.replace(\"'\",'')\n",
    "    cleaned_text = cleaned_text.lower()\n",
    "    return(cleaned_text)\n",
    "\n",
    "#cleaned_text = clean_text(text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Majuscules et minuscules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zinedine zidane france\n"
     ]
    }
   ],
   "source": [
    "# Lower\n",
    "words = \"Zinedine Zidane FRANCE\"\n",
    "new_words = words.lower()\n",
    "print(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En termes généraux, la scence des données est l'extraction de conaissance d'ensembles de données.   \n",
      " \n",
      "Elle emploie des techniques et des théories tirées de plusieurs autres domaines plus larges des mathématiques, la statistique principalement, la téorie de l'information et la technologie de l'information, notamment le traitement de signal, des modèles probabilistes, l'apprentissage automatique, l'apprentissage statistiqe, la programmation informatique, l'ingénierie de données, la reconnaissance de formes et l'apprentissage, la visualisation, l'analytique prophétique, la modélisation d'incertitude, le stokage de données, la compression de données et le calcul à haute performance. \n",
      " \n",
      "Les méthodes qui s'adaptent aux données de masse sont particulièrement intéressantes dans la science des données, bien que la dicipline ne soit généralement pas considérée come limitée à ces données.   \n",
      " \n",
      "Le premier objectif est de produire des méthodes automatisées, autant que possible de tri et d'analyse de données de masse et de sources plus ou moins complexes ou disjointes de données, afin d'en extraire des informations utiles ou potentiellement utiles. Source Wikipédia\n"
     ]
    }
   ],
   "source": [
    "# Clean modifiée\n",
    "\n",
    "def clean_text(string):\n",
    "    cleaned_text = string.replace(',','')\n",
    "    cleaned_text = cleaned_text.replace('.','')\n",
    "    cleaned_text = cleaned_text.replace('\\n', '')\n",
    "    cleaned_text = cleaned_text.replace(\"'\",'')\n",
    "    cleaned_text = cleaned_text.lower()\n",
    "    return(cleaned_text)\n",
    "\n",
    "#cleaned_text = clean_text(text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arguments Multiples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    " def clean_string(string, change_string):\n",
    "    replacement_string=\"\"\n",
    "    cleaned_string = string.replace(change_string, replacement_string)\n",
    "    return cleaned_string\n",
    "\n",
    "goal=clean_string('GOAAALL!!!!!', '!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOAAALL\n"
     ]
    }
   ],
   "source": [
    "print(goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOAAAALLL!!!!!\n"
     ]
    }
   ],
   "source": [
    "def modify_text(string, modify_string, replacement_string):\n",
    "    cleaned_string = string.replace(modify_string,replacement_string)\n",
    "    return(cleaned_string)\n",
    "\n",
    "goal = modify_text('GOAAAALLL.....','.','!')\n",
    "print(goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en termes généraux la scence des données est lextraction de conaissance densembles de données    elle emploie des techniques et des théories tirées de plusieurs autres domaines plus larges des mathématiques la statistique principalement la téorie de linformation et la technologie de linformation notamment le traitement de signal des modèles probabilistes lapprentissage automatique lapprentissage statistiqe la programmation informatique lingénierie de données la reconnaissance de formes et lapprentissage la visualisation lanalytique prophétique la modélisation dincertitude le stokage de données la compression de données et le calcul à haute performance  les méthodes qui sadaptent aux données de masse sont particulièrement intéressantes dans la science des données bien que la dicipline ne soit généralement pas considérée come limitée à ces données    le premier objectif est de produire des méthodes automatisées autant que possible de tri et danalyse de données de masse et de sources plus ou moins complexes ou disjointes de données afin den extraire des informations utiles ou potentiellement utiles source wikipédia\n"
     ]
    }
   ],
   "source": [
    "#print(text)\n",
    "def clean_text(string, special_caracters, replacement_string):\n",
    "    cleaned_text = string\n",
    "    for char in special_caracters:\n",
    "        cleaned_text = cleaned_text.replace(char, replacement_string)\n",
    "    cleaned_text = cleaned_text.lower()\n",
    "    return(cleaned_text)\n",
    "\n",
    "new_text = clean_text(text, [',',\"'\",'.','\\n'], '')\n",
    "print(new_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization du fichier texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['en', 'termes', 'généraux', 'la', 'scence', 'des', 'données', 'est', 'lextraction', 'de']\n"
     ]
    }
   ],
   "source": [
    "def tokenized(string, special_caracters, replacement_string):\n",
    "        tokenized_text = clean_text(string, special_caracters, replacement_string)\n",
    "        tokenized_text = tokenized_text.split(' ')\n",
    "        return(tokenized_text)\n",
    "\n",
    "tokenized_words = tokenized(text, [',',\"'\",'.','\\n'], '')\n",
    "print(tokenized_words[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trouver les mots faux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "misspelled_words = []\n",
    "\n",
    "for word in tokenized_words:\n",
    "    if word  not in tokenized_voc:\n",
    "         misspelled_words.append(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['scence', 'conaissance', '', '', '', 'téorie', 'statistiqe', 'stokage', '', 'dicipline', 'come', '', '', '']\n"
     ]
    }
   ],
   "source": [
    "print(misspelled_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amélioration !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['scence', 'conaissance', 'téorie', 'statistiqe', 'stokage', 'dicipline', 'come']\n"
     ]
    }
   ],
   "source": [
    "def spell_check(vocabulary_file,text_file,special_caracters=[',',\"'\",'.','\\n'], replacement_string=\"\"):\n",
    "    misspelled_words = []\n",
    "    voc = open(vocabulary_file,'r',encoding='utf-8').read()\n",
    "    text = open(text_file,'r',encoding='utf-8').read()\n",
    "    tokenized_voc = tokenized(voc,special_caracters, replacement_string)\n",
    "    tokenized_text = tokenized(text,special_caracters, replacement_string)\n",
    "    for word in tokenized_text:\n",
    "        if word not in tokenized_voc:\n",
    "            if word != \"\":\n",
    "                misspelled_words.append(word)\n",
    "    return(misspelled_words)\n",
    "\n",
    "final_misspelled_words = spell_check(vocabulary_file ='dictionnaire.txt',text_file='texte.txt')\n",
    "print(final_misspelled_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Types d'erreurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syntax Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exemples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-64-41c49651e397>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-64-41c49651e397>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    answer = 42\"\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "answer = 42\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-65-2b8c087a1c28>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-65-2b8c087a1c28>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    de fonction():\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "de fonction():\n",
    "    print('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-66-ee0d82a80d43>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-66-ee0d82a80d43>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    print('t'es sur ?')\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "def nine():\n",
    "    print('9')\n",
    "        print('t'es sur ?')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runtime Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemples : type error et value error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "nine = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-2cfc5b761e7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnine\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"2\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'str'"
     ]
    }
   ],
   "source": [
    "nine + \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'bonjour'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-39460a0b5ef2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bonjour\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'bonjour'"
     ]
    }
   ],
   "source": [
    "float(\"bonjour\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autres exemples de runtime error :\n",
    "# indexError // attributeError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-081245e92ea6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m65\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "ages = [12,15,65]\n",
    "ages[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'_io.TextIOWrapper' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-0e523f7a14f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'texte.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#.read()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: '_io.TextIOWrapper' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "f = open('texte.txt')#.read()\n",
    "f.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
